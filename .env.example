# Example environment variables for llmdy

OPENAI_API_KEY=anything

# Wherever your ReaderLM model is hosted, you can set the base URL here.
OPENAI_BASE_URL=http://localhost:8080/v1

# The name of the readerlm model returned from /v1/models
READERLM_MODEL=models/readerlm-v2

# The strategy to use for caching. Options are 'redis', 'memory', 'none'
# If llmdy is deployed in a memory-restricted environment, you should not use 'memory'
CACHE_STRATEGY=memory

# How long to keep a generated markdown before it is considered stale and needs to be generated again. This field is in seconds.
CACHE_TTL=3600

# In the case of interruption during markdown generation, there are ways to continue an incomplete generation. Options are 'redis', 'disk', 'none'
# By setting this to 'none', if generation fails midway, you will have to restart the entire generation. It is recommended to set this to 'disk', or 
# if you are on a serverless environment, set this to 'redis'
RECOVERY_STRATEGY=disk

# the URI to the Redis instance
REDIS_URI=